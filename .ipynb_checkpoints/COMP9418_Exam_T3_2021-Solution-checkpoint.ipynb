{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T3-2021 Exam\n",
    "\n",
    "**COMP9418 - Advanced Topics in Statistical Machine Learning**\n",
    "\n",
    "**University of New South Wales**\n",
    "\n",
    "**7th December, 2021**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, please read and acknowledge the following (double-click on this cell and put an `X` between the brackets `[X]`):\n",
    "    \n",
    "- [ ] I acknowledge that I will complete all of the work I submit for this exam without assistance from anyone else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Instructions\n",
    "\n",
    "1. This exam will last for 12 hours, starting 7/12/2021 at 09:00:00 AEDT and ending 7/12/2021 at 21:00:00 AEDT.\n",
    "2. Questions will be answered from 9 am to 9 pm AEDT. Questions should be posted in the [WebCMS forum]\n",
    "3. You must provide all answers in this Jupyter notebook. \n",
    "4. You must use the cells provided to answer the questions. Use markdown cells for textual answers and code cells for programming answers.\n",
    "5. Submit this exam by give (command line or WebCMS) before the deadline. If WebCMS submission is slow, or if you are submitting in the last hour, please submit using the give command on the CSE servers (via VLAB or ssh).\n",
    "The appropriate command is ```give cs9418 exam *.ipynb```. We will not accept late submissions.\n",
    "6. The exam has three parts: Multiple choice questions (20%); Questions that require a textual answer (50%); and, programming questions in Python (30%).\n",
    "7. This exam is an open book exam. You are permitted to access papers and books as well as the course materials, including slides and solved tutorials. Please, in case of doubt, read the [UNSW guidance on open book exams](https://student.unsw.edu.au/open-book-and-take-home-exams).\n",
    "8. You are not permitted to communicate (email, phone, message, talk, etc.) with anyone during the exam, except COMP9418 staff via email or forum.\n",
    "9. Do not communicate your exam answers after you finish your exam. Some students may have extended time to complete the exam.\n",
    "10. Do not place your exam work in any location accessible to any other person, such as  Dropbox and Github.\n",
    "11. Ensure that no other person in your household can access your work.\n",
    "12. Do not disclose your zpass to any other person. If you have revealed your zpass, you should change it immediately.\n",
    "13. We will refer deliberate violations of exam conditions to Student Integrity as serious misconduct. \n",
    "14. This exam has nine questions. The total number of marks is 100.\n",
    "15. **Type your student number and name on the next cell.**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student identification\n",
    "\n",
    "**Name:**\n",
    "\n",
    "**Student ID:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiscreteFactors import Factor\n",
    "from Graph import Graph\n",
    "from BayesNet import BayesNet\n",
    "from GaussianFactor import GaussianFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 [20 marks]\n",
    "\n",
    "Part 1 is composed of four multiple-choice questions of five marks each. To answer each question, double-click the cell with the alternatives and write an `X` between the `[ ]` of the chosen option.\n",
    "\n",
    "This is an example before inserting `X`\n",
    "\n",
    "1. [ ] Alternative one\n",
    "2. [ ] Alternative two\n",
    "\n",
    "This is an example after inserting `X`\n",
    "\n",
    "1. [X] Alternative one\n",
    "2. [ ] Alternative two\n",
    "\n",
    "For all four questions, choose only one among the alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 1 [5 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the directed Graph $G_D$ (left) and the undirected graph $G_U$ (right). Also, consider the probabilities distributions $P_D$ and $P_U$ that factorise according to $G_D$ and $G_U$, respectively. Select the **correct** alternative regarding graph separation and probability independence.\n",
    "\n",
    "![Graphs GD and GU](images/Question_separation.png \"Graph GD and GU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [ ] $dsep_{G_D}(B,F,D)$ and $sep_{G_U}(B,F,D)$. Therefore, $B \\perp D | F$ in both $P_D$ and $P_U$.\n",
    "2. [ ] $dsep_{G_D}(C,\\emptyset,D)$ and $sep_{G_U}(C,\\emptyset,D)$. Therefore, $C \\perp D$ in both $P_D$ and $P_U$.\n",
    "3. [ ] $\\neg dsep_{G_D}(B,F,D)$ and $\\neg sep_{G_U}(B,F,D)$. Therefore, $B \\not\\perp D | F$ in $P_D$ and $B \\not\\perp D | F$ in $P_U$.\n",
    "4. [ ] $\\neg dsep_{G_D}(B,F,D)$ and $\\neg sep_{G_U}(C,\\emptyset,D)$. Therefore, $B \\not\\perp D | F$ in $P_D$ and $C \\not\\perp D$ in $P_U$.\n",
    "5. [X] None of the above alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 2 [5 marks]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose we apply the Expectation-Maximization (EM) approach to learning parameters from a complete (with no missing values) dataset. Choose the correct alternative:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [X] EM will converge in a single iteration, and it will return the maximum-likelihood estimates independent of the initial parameter values.\n",
    "2. [ ] EM will converge in one or more iterations, and it will return the maximum-likelihood estimates independent of the initial parameter values.\n",
    "3. [ ] EM will often converge to the maximum-likelihood estimates, but it will depend on the quality of the initial parameter values.\n",
    "4. [ ] EM will not converge to the maximum-likelihood estimates.\n",
    "5. [ ] EM is not applicable to complete data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 3 [5 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we used the Variable Elimination algorithm on a Gaussian Bayesian Network with elimination order $o$. The network has $N$ variables and the width of the network with elimination order $o$ is $w$. \n",
    "What is the time complexity of this algorithm? Choose the option with the tightest upper bound.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [ ] $N e^w$\n",
    "2. [ ] $N w^3$\n",
    "3. [X] $N w^2$\n",
    "4. [ ] $N w$\n",
    "5. [ ] $N \\log w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 4 [5 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following three directed graphs, $G_1$, $G_2$ and $G_3$. \n",
    "\n",
    "![Graphs G1 G2 and G3](images/Question_MDL.png \"Graphs G_1, G_2 and G_3\")\n",
    "\n",
    "On a dataset $D$, $G_1$ has a log-likelihood of -32.4, $G_2$ has log-likelihood  of -28.3, and $G_3$ has log-likelihood of -15.2. $D$ contains 64 data points and six binary variables. Rank the three graphs using the Minimum Description Length (MDL) score, from best to worst on the dataset $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [ ] $G_1, G_2, G_3$\n",
    "2. [X] $G_1, G_3, G_2$\n",
    "3. [ ] $G_2, G_3, G_1$\n",
    "4. [ ] $G_3, G_2, G_1$\n",
    "5. [ ] $G_3, G_1, G_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2 [50 marks]\n",
    "\n",
    "Part 2 is composed of three open questions. To answer each question, edit the markdown cell after the question statement and insert your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 5 [20 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andy and Lance are two metal detectorists that like to work together. Their hobby consists of using metal detectors to find buried metallic objects (targets). Andy uses an XP metal detector, while Lance operates a Minelab. When searching for a buried target, they both measure their machines' response before excavating the target. A target can be trash (bottle caps, cans, nails, etc.) or treasure (coins, rings, historical artefacts, etc.). \n",
    "\n",
    "The XP correctly recognises trash with 90% accuracy but has a lower accuracy in identifying treasure correctly, 70%. The Minelab machine identifies trash and treasure correctly with 80% and 70% accuracy, respectively. \n",
    "\n",
    "Both detectors are sensitive machines that may require calibration from time to time. The XP is a more robust machine, and the probability of being uncalibrated is only 1%. The Minelab has a higher chance of being uncalibrated, 5%. An uncalibrated device has its accuracy for detecting treasure reduced by 10% while leaving the trash accuracy unmodified. \n",
    "\n",
    "Given that 99% of the detected objects are trash, what is the probability of a target being a treasure given that both machines read treasure?\n",
    "\n",
    "1. [**5 Marks**] Show a Bayesian network structure (graph) for this problem. \n",
    "2. [**5 Marks**] **Briefly** explain your network.\n",
    "3. [**5 Marks**] Show the outcome space and network conditional probability tables (CPTs) for all variables. If any information is missing, assume a uniform distribution.\n",
    "4. [**5 Marks**] What is the answer to this question? Solve it as a programming exercise, i.e., provide a program that computes the solution. Is the numerical solution what you expect? **Briefly** comment on the resulting probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.49.3 (20211023.0002)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"350pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 350.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 346,-112 346,4 -4,4\"/>\n",
       "<!-- T -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"171\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"171\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M155.73,-74.73C145.8,-64.8 132.68,-51.68 121.56,-40.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"123.79,-37.84 114.25,-33.25 118.84,-42.79 123.79,-37.84\"/>\n",
       "</g>\n",
       "<!-- M -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>M</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"243\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">M</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;M -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;M</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M186.27,-74.73C196.2,-64.8 209.32,-51.68 220.44,-40.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"223.16,-42.79 227.75,-33.25 218.21,-37.84 223.16,-42.79\"/>\n",
       "</g>\n",
       "<!-- CX -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>CX</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">CX</text>\n",
       "</g>\n",
       "<!-- CX&#45;&gt;X -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>CX&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M42.27,-74.73C52.2,-64.8 65.32,-51.68 76.44,-40.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.16,-42.79 83.75,-33.25 74.21,-37.84 79.16,-42.79\"/>\n",
       "</g>\n",
       "<!-- CM -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>CM</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"315\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"315\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">CM</text>\n",
       "</g>\n",
       "<!-- CM&#45;&gt;M -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>CM&#45;&gt;M</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M299.73,-74.73C289.8,-64.8 276.68,-51.68 265.56,-40.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"267.79,-37.84 258.25,-33.25 262.84,-42.79 267.79,-37.84\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1effb6a9d60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer for 1 - Bayesian network structure\n",
    "\n",
    "# Define your graph here\n",
    "G = Graph({\n",
    "    'T': ('X', 'M'),\n",
    "    'CX': ('X'),\n",
    "    'CM': ('M'),    \n",
    "    'X': (),\n",
    "    'M': (),    \n",
    "})\n",
    "\n",
    "# To improve visualisation\n",
    "pos = {\n",
    "    'CX': '1,1!',\n",
    "    'T': '3,1!',\n",
    "    'CM': '5,1!',\n",
    "    'X': '2,0!',\n",
    "    'M': '4,0!',\n",
    "}\n",
    "\n",
    "G.show(positions=pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 2**\n",
    "\n",
    "Variables:\n",
    "1. $T$: Target, it can assume values 'treasure' or 'trash'\n",
    "2. $CX$: Calibration XP, it can assume values 'calibrated' or 'uncalibrated'\n",
    "3. $CM$: Calibration Minelab, it can assume values 'calibrated' or 'uncalibrated'\n",
    "4. $X$: XP, it can assime values 'treasure' or 'trash'\n",
    "5. $M$: Minelab, it can assime values 'treasure' or 'trash'\n",
    "\n",
    "Both XP and Minelab readings can be influenced by the target under them and their calibration state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer for 3\n",
    "\n",
    "outcomeSpace = dict(\n",
    "    T=('treasure', 'trash'),\n",
    "    CX=('calibrated', 'uncalibrated'),\n",
    "    CM=('calibrated', 'uncalibrated'),    \n",
    "    X=('treasure', 'trash'),\n",
    "    M=('treasure', 'trash'),\n",
    ")\n",
    "\n",
    "BN = BayesNet(G, outcomeSpace)\n",
    "\n",
    "T_prob = Factor(('T',), outcomeSpace)\n",
    "T_prob['treasure'] = 0.01\n",
    "T_prob['trash'] = 0.99\n",
    "BN.factors['T'] = T_prob\n",
    "\n",
    "CX_prob = Factor(('CX',), outcomeSpace)\n",
    "CX_prob['calibrated'] = 0.01\n",
    "CX_prob['uncalibrated'] = 0.99\n",
    "BN.factors['CX'] = CX_prob\n",
    "\n",
    "CM_prob = Factor(('CM',), outcomeSpace)\n",
    "CM_prob['calibrated'] = 0.05\n",
    "CM_prob['uncalibrated'] = 0.95\n",
    "BN.factors['CM'] = CM_prob\n",
    "\n",
    "X_prob = Factor(('CX', 'T', 'X'), outcomeSpace)\n",
    "X_prob['calibrated', 'treasure', 'treasure'] = 0.7\n",
    "X_prob['calibrated', 'treasure', 'trash'] = 0.3\n",
    "X_prob['calibrated', 'trash', 'treasure'] = 0.1\n",
    "X_prob['calibrated', 'trash', 'trash'] = 0.9\n",
    "X_prob['uncalibrated', 'treasure', 'treasure'] = 0.63\n",
    "X_prob['uncalibrated', 'treasure', 'trash'] = 0.37\n",
    "X_prob['uncalibrated', 'trash', 'treasure'] = 0.1\n",
    "X_prob['uncalibrated', 'trash', 'trash'] = 0.9\n",
    "\n",
    "# Students may also use these probabilities in the case \n",
    "# they understand that the accuracy should reduce in \n",
    "# 10 percentual points\n",
    "# X_prob['uncalibrated', 'treasure', 'treasure'] = 0.6\n",
    "# X_prob['uncalibrated', 'treasure', 'trash'] = 0.3\n",
    "# X_prob['uncalibrated', 'trash', 'treasure'] = 0.1\n",
    "# X_prob['uncalibrated', 'trash', 'trash'] = 0.9\n",
    "\n",
    "BN.factors['X'] = X_prob\n",
    "\n",
    "M_prob = Factor(('CM', 'T', 'M'), outcomeSpace)\n",
    "M_prob['calibrated', 'treasure', 'treasure'] = 0.8\n",
    "M_prob['calibrated', 'treasure', 'trash'] = 0.2\n",
    "M_prob['calibrated', 'trash', 'treasure'] = 0.3\n",
    "M_prob['calibrated', 'trash', 'trash'] = 0.7\n",
    "M_prob['uncalibrated', 'treasure', 'treasure'] = 0.72\n",
    "M_prob['uncalibrated', 'treasure', 'trash'] = 0.28\n",
    "M_prob['uncalibrated', 'trash', 'treasure'] = 0.1\n",
    "M_prob['uncalibrated', 'trash', 'trash'] = 0.9\n",
    "\n",
    "# Students may also use these probabilities in the case \n",
    "# they understand that the accuracy should reduce in \n",
    "# 10 percentual points\n",
    "# M_prob['uncalibrated', 'treasure', 'treasure'] = 0.7\n",
    "# M_prob['uncalibrated', 'treasure', 'trash'] = 0.3\n",
    "# M_prob['uncalibrated', 'trash', 'treasure'] = 0.1\n",
    "# M_prob['uncalibrated', 'trash', 'trash'] = 0.9\n",
    "\n",
    "BN.factors['M'] = M_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════╤══════════╕\n",
      "│ T        │       Pr │\n",
      "╞══════════╪══════════╡\n",
      "│ treasure │ 0.295431 │\n",
      "├──────────┼──────────┤\n",
      "│ trash    │ 0.704569 │\n",
      "╘══════════╧══════════╛\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your answer for 4\n",
    "Q = BN.query(('T',), X='treasure', M='treasure')\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Briefly comment on the results of 4**\n",
    "\n",
    "$P(T=treasure|X=treasure, M=treasure)$ is a bit low apart both machines indicating it is a tresure. \n",
    "This happens because the prior probability of a target being treasure is very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 6 [15 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 10 discussed MAP queries. We developed the MPE VE and MAP VE algorithms based on the Variable Elimination (VE) algorithm. In lecture 11, we learned about jointrees. Suppose we want to replace the VE algorithm with the jointree algorithm for computing MAP and MPE queries. Answer the following questions:\n",
    "\n",
    "1. How can we redefine the jointree messages to answer maximum a posteriori queries?\n",
    "2. Will this new algorithm work for both MAP and MPE queries? **Briefly explain**.\n",
    "3. What are the benefits and limitations of this new approach compared with variable elimination?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 1**\n",
    "\n",
    "There are two approaches for this problem.\n",
    "\n",
    "In the first one, we can modify the messages to use maxization instead of summation. Therefore, the clusters will store max marginals instead of beliefs. A message defined in the lectures as \n",
    "\n",
    "$M_{ij} =\\sum_{C_{i}\\backslash S_{ij}} \\Phi_{i}\\prod_{k\\neq j}M_{ki}$\n",
    "\n",
    "is redefined as\n",
    "\n",
    "$M_{ij} =\\max_{C_{i}\\backslash S_{ij}} \\Phi_{i}\\prod_{k\\neq j}M_{ki}$\n",
    "\n",
    "In the second approach, we can compute MAP queries with the original jointree messages and maximize out variables in the clusters. In this case, the approach is limited to queries in which the MAP variables are in a same cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 2**\n",
    "\n",
    "The first approach only works for MPE queries. MAP queries involve summing out non-MAP variables before maximize out MAP variables. Since we pass messages between all clusters, we do not have control of the order of the max and sum operations.\n",
    "\n",
    "The second approach works for MAP queries, but it is limited to the case MAP variables are in a same cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 3**\n",
    "\n",
    "Both approaches allow us to compute answers to multiple queries. However, the first approach is limited to MPE queries while the second to MAP queries where the MAP variables are in a single cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 7 [15 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lecture 15, we performed inference by creating and counting samples. We generated those samples by simulating a Bayesian Network $N$, and we learned that this simulation could be difficult in the presence of evidence. Now, suppose we have a jointree with cluster marginals $P(C_i|\\textbf{e})$ and separator marginals $P(S_{ij}|\\textbf{e})$ obtained with the execution of the jointree algorithm on the network $N$ and evidence $\\textbf{e}$.\n",
    "\n",
    "1. Provide an efﬁcient algorithm for simulating $N$ conditioned on $\\textbf{e}$ given the cluster and separator marginals. \n",
    "2. Argue that your algorithm generates a sequence of independent network instantiations $x_1, ... , x_n$ where the probability of generating an instance $x_i$ is $P(x_i|\\textbf{e})$.\n",
    "3. Discuss the complexity of your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 1**\n",
    "\n",
    "Input: Jointree $J$ with clusters $\\textbf{C}_i$ and separators $\\textbf{S}_{ij}$ <br />\n",
    "$~~~~~~~~~$ Evidence $\\textbf{e}$ <br />\n",
    "Output: Instantiation $\\Sigma$ <br />\n",
    "\n",
    "1. $\\Sigma \\leftarrow \\textbf{e}$<br />\n",
    "2. Start a depth-first search from a random cluster $\\textbf{C}_i$<br />\n",
    "3. While not all non-evidence variables are sampled\n",
    "4. $~~~~~$$\\sigma \\leftarrow$ random instantiation of variables in $\\textbf{C}_i\\backslash\\textbf{e}$ according $P(\\textbf{C}_i|\\textbf{e})$<br />\n",
    "5. $~~~~~$$\\Sigma \\leftarrow \\Sigma \\cup \\sigma$<br />\n",
    "6. $~~~~~$Find in DFS order a neighbouring cluster to $\\textbf{C}_i$. Call this new cluster $\\textbf{C}_j$<br />\n",
    "7. $~~~~~$Set evidence in $\\textbf{C}_j$ according to $\\textbf{S}_{ij} = \\sigma$<br />\n",
    "8. $~~~~~$$\\textbf{e} \\leftarrow \\textbf{e} \\cup S_{ij} = \\sigma$<br />\n",
    "9. $~~~~~$Rename $\\textbf{C}_j$ as $\\textbf{C}_i$\n",
    "10. return $\\Sigma$\n",
    "\n",
    "Remarks:\n",
    "- We need to move in DFS order or any order that let us visit the clusters according to the jointree structure. If we pick the clusters in random order, setting evidence is insufficient to provide the correct results. We may have a long chain of influence such as $A \\rightarrow B \\rightarrow C \\rightarrow D ...$. \n",
    "- We can generate an instantiation for all variables in $\\textbf{C}_i\\backslash\\textbf{e}$ in a single step. The procedure generates a number between $[0..1]$ and checks which instantiation the random number falls in. Although generating the random number is $O(1)$, finding out the instantiation is $O(\\exp(|\\textbf{C}_i|))$ with a naive linear search.\n",
    "- There is no need to follow topological order, as it happens for Bayesian networks. Topological order was used for Bayes nets because nodes store conditional probabilities of variables given parents. \n",
    "- The clusters store joint marginal probabilities. We can set evidence by zeroing rows that do not conform with evidence and renormalising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 2**\n",
    "\n",
    "This algorithm uses the marginals provided by the clusters of the jointree. All marginals are \"calibrated\", i.e., computing $P(X)$ results in the same probabilities for any marginal $M$ that contains $X$.\n",
    "\n",
    "As we know, the jointree has the correct marginals for the associated Bayesian network. Also, the marginals have already incorporated evidence. Therefore, there is no need for rejection sampling, and we do not sample the evidence.\n",
    "\n",
    "The first cluster is sampled according to $P(\\textbf{C}_i|\\textbf{e})$. The remaining ones are sampled according to $P(\\textbf{C}_j|\\textbf{C}_i = \\sigma, \\textbf{e})$. We carefully add more evidence as we sample the jointree clusters, respecting the jointree structure. This step is important so we respect long chaing of influence between variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 3**\n",
    "\n",
    "This analysis assumes that the simulation procedure generates only one sample. The jointree $J$ is already computed according to the evidence.\n",
    "\n",
    "Given that we have $n$ clusters in $J$, the DFS procedure visits each cluster once. During each visit, the algorithm executes steps 4 to 9. The most expensive step is 4 that requires searching the table that stores $P(\\textbf{C}_i|\\textbf{e})$. This table has size $O(\\exp(|\\textbf{C}_i|))$.\n",
    "\n",
    "Therefore, the complexity is $O(n \\exp(w))$, being $w$ the number of variables in the largest cluster. We can create an indexing structure for searching the instantiation. However, this index does not improve the complexity for a single sample, although it has a better-amortised complexity when generating more samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3 [30 marks]\n",
    "\n",
    "Part 3 is composed of two programming questions of 15 marks each. Use the code cell after each question statement to enter your answer. You can use the code of the tutorials in your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 8 [15 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lecture 11, we learned about jointrees. These probabilistic graphical models must obey a property known as *running intersection* to be considered proper jointrees. Implement a function ``RIP(J)`` that returns **true** if the jointree ``J`` obeys the running intersection property and **false** otherwise. The argument `J` is a jointree object as defined in the tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our answer for Question 8 here\n",
    "\n",
    "def sep(v, w):\n",
    "    if v < w:\n",
    "        return str(v)+str(w)\n",
    "    else:\n",
    "        return str(w)+str(v)\n",
    "\n",
    "def RIP_dfs(J, v, var): \n",
    "    colour = {node: 'white' for node in J.graph} \n",
    "    return RIP_dfs_r(J, v, var, colour)\n",
    "\n",
    "def RIP_dfs_r(J, v, var, colour, state = True):\n",
    "    colour[v] = 'gray'\n",
    "    if state:\n",
    "        if var not in J.clusters[v]:\n",
    "            return False\n",
    "    else:\n",
    "        if var in J.clusters[v]:\n",
    "            return False\n",
    "        \n",
    "    for w in J.graph.adj_list[v]:\n",
    "        if colour[w] == 'white':\n",
    "            if var in J.separators[sep(v, w)]:\n",
    "                if state:\n",
    "                    return RIP_dfs_r(J, w, var, colour)\n",
    "                else:\n",
    "                    return False\n",
    "            else:\n",
    "                return RIP_dfs_r(J, w, var, colour, False)\n",
    "    return True\n",
    "\n",
    "def RIP(J):\n",
    "    for v in J.clusters:\n",
    "        for var in J.clusters[v]:\n",
    "            if not RIP_dfs(J, v, var):\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# Test code\n",
    "\n",
    "class JoinTree():\n",
    "    def __init__(self, graph, clusters, separators):\n",
    "        self.graph = graph\n",
    "        self.separators = separators\n",
    "        self.clusters = clusters\n",
    "\n",
    "G = Graph({\n",
    "    '1': ('2', ),\n",
    "    '2': ('1', '3', '4'),\n",
    "    '3': ('2', ),\n",
    "    '4': ('2', '5'),\n",
    "    '5': ('4', ),\n",
    "})\n",
    "\n",
    "S = {\n",
    "    '12': ('S', 'V'),\n",
    "    '23': ('V', ),\n",
    "    '24': ('O', ),\n",
    "    '45': ('T', ),\n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('S', 'L', 'H', 'V'),\n",
    "    '2': ('O', 'S', 'V'),\n",
    "    '3': ('C', 'V'),\n",
    "    '4': ('B', 'O', 'T'),\n",
    "    '5': ('A', 'T'),\n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Hidden test cases\n",
    "\n",
    "marks = 0\n",
    "\n",
    "G = Graph({\n",
    "    '1': ('2', ),\n",
    "    '2': ('1', '3', '4'),\n",
    "    '3': ('2', ),\n",
    "    '4': ('2', '5'),\n",
    "    '5': ('4', ),\n",
    "})\n",
    "\n",
    "S = {\n",
    "    '12': ('S', 'V'),\n",
    "    '23': ('V', ),\n",
    "    '24': ('O', ),\n",
    "    '45': ('T', ),\n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('S', 'L', 'H', 'V'),\n",
    "    '2': ('O', 'S', 'V'),\n",
    "    '3': ('C', 'V'),\n",
    "    '4': ('B', 'O', 'T'),\n",
    "    '5': ('A', 'T'),\n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if RIP(jt):\n",
    "    marks += 1\n",
    "\n",
    "G = Graph({\n",
    "    '1': ('2', ),\n",
    "    '2': ('1', '3', '4'),\n",
    "    '3': ('2', ),\n",
    "    '4': ('2', '5'),\n",
    "    '5': ('4', ),\n",
    "})\n",
    "\n",
    "S = {\n",
    "    '12': ('S', ),\n",
    "    '23': (),\n",
    "    '24': ('O', ),\n",
    "    '45': ('T', ),\n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('S', 'L', 'H', 'V'),\n",
    "    '2': ('O', 'S'),\n",
    "    '3': ('C', 'V'),\n",
    "    '4': ('B', 'O', 'T'),\n",
    "    '5': ('A', 'T'),\n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if not RIP(jt):\n",
    "    marks += 1\n",
    "\n",
    "G = Graph({\n",
    "    '1': (),\n",
    "})\n",
    "\n",
    "S = {\n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('S', 'L', 'H', 'V'),\n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if RIP(jt):\n",
    "    marks += 1\n",
    "\n",
    "G = Graph({\n",
    "    '1': ('3', ),\n",
    "    '2': ('4', ),\n",
    "    '3': ('1', '4', '5'),\n",
    "    '4': ('2', '3', '6'),\n",
    "    '5': ('3', ),\n",
    "    '6': ('4', ),    \n",
    "})\n",
    "\n",
    "S = {\n",
    "    '13': ('D', 'F'),\n",
    "    '24': ('A', 'E'),\n",
    "    '34': ('A', 'F'),\n",
    "    '35': ('A', 'D'),\n",
    "    '46': ('E', 'F'),    \n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('F', 'D', 'G'),\n",
    "    '2': ('A', 'C', 'E'),\n",
    "    '3': ('A', 'D', 'F'),\n",
    "    '4': ('A', 'E', 'F'),\n",
    "    '5': ('A', 'B', 'D'),\n",
    "    '6': ('E', 'F', 'H'),    \n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if RIP(jt):\n",
    "    marks += 1\n",
    "\n",
    "G = Graph({\n",
    "    '1': ('3', ),\n",
    "    '2': ('4', ),\n",
    "    '3': ('1', '4', '5'),\n",
    "    '4': ('2', '3', '6'),\n",
    "    '5': ('3', ),\n",
    "    '6': ('4', ),    \n",
    "})\n",
    "\n",
    "S = {\n",
    "    '13': ('D', 'F'),\n",
    "    '24': ('E'),\n",
    "    '34': ('F'),\n",
    "    '35': ('A', 'D'),\n",
    "    '46': ('E', 'F'),    \n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('F', 'D', 'G'),\n",
    "    '2': ('A', 'C', 'E'),\n",
    "    '3': ('A', 'D', 'F'),\n",
    "    '4': ('E', 'F'),\n",
    "    '5': ('A', 'B', 'D'),\n",
    "    '6': ('E', 'F', 'H'),    \n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if not RIP(jt):\n",
    "    marks += 1\n",
    "\n",
    "G = Graph({\n",
    "    '1': ('3', ),\n",
    "    '2': ('4', ),\n",
    "    '3': ('1', '4', '5'),\n",
    "    '4': ('2', '3', '6'),\n",
    "    '5': ('3', ),\n",
    "    '6': ('4', ),    \n",
    "})\n",
    "\n",
    "S = {\n",
    "    '13': ('A', 'D', 'F'),\n",
    "    '24': ('E', ),\n",
    "    '34': ('F', ),\n",
    "    '35': ('A', 'D'),\n",
    "    '46': ('E', 'F'),    \n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('A', 'F', 'D', 'G'),\n",
    "    '2': ('A', 'C', 'E'),\n",
    "    '3': ('A', 'D', 'F'),\n",
    "    '4': ('E', 'F'),\n",
    "    '5': ('A', 'B', 'D'),\n",
    "    '6': ('E', 'F', 'H'),    \n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if not RIP(jt):\n",
    "    marks += 1\n",
    "    \n",
    "G = Graph({\n",
    "    '1': ('3',),\n",
    "    '2': ('4'),\n",
    "    '3': ('1', '4', '5'),\n",
    "    '4': ('2', '3', '6'),\n",
    "    '5': ('3',),\n",
    "    '6': ('4',),    \n",
    "})\n",
    "\n",
    "S = {\n",
    "    '13': ('A', 'D', 'F'),\n",
    "    '24': ('A', 'E'),\n",
    "    '34': ('A', 'F'),\n",
    "    '35': ('A', 'D'),\n",
    "    '46': ('A', 'E', 'F'),    \n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('A', 'F', 'D', 'G'),\n",
    "    '2': ('A', 'C', 'E'),\n",
    "    '3': ('A', 'D', 'F'),\n",
    "    '4': ('A', 'E', 'F'),\n",
    "    '5': ('A', 'B', 'D'),\n",
    "    '6': ('A', 'E', 'F', 'H'),    \n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if RIP(jt):\n",
    "    marks += 1\n",
    "    \n",
    "G = Graph({\n",
    "    '1': ('3',),\n",
    "    '2': ('4'),\n",
    "    '3': ('1', '4', '5'),\n",
    "    '4': ('2', '3', '6'),\n",
    "    '5': ('3',),\n",
    "    '6': ('4',),    \n",
    "})\n",
    "\n",
    "S = {\n",
    "    '13': ('D', 'F'),\n",
    "    '24': ('A', 'E'),\n",
    "    '34': ('F', ),\n",
    "    '35': ('D', ),\n",
    "    '46': ('A', 'E', 'F'),    \n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('A', 'F', 'D', 'G'),\n",
    "    '2': ('A', 'C', 'E'),\n",
    "    '3': ('D', 'F'),\n",
    "    '4': ('A', 'E', 'F'),\n",
    "    '5': ('A', 'B', 'D'),\n",
    "    '6': ('A', 'E', 'F', 'H'),    \n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if not RIP(jt):\n",
    "    marks += 1\n",
    "\n",
    "G = Graph({\n",
    "    '1': ('2', ),\n",
    "    '2': ('1', '3'),\n",
    "    '3': ('2', '4'),\n",
    "    '4': ('3', '5'),\n",
    "    '5': ('4', ),\n",
    "})\n",
    "\n",
    "S = {\n",
    "    '12': ('A', 'B'),\n",
    "    '23': ('A', 'B'),\n",
    "    '34': ('A', 'B'),\n",
    "    '45': ('A', 'B'),\n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('A', 'B'),\n",
    "    '2': ('A', 'B'),\n",
    "    '3': ('A', 'B'),\n",
    "    '4': ('A', 'B'),\n",
    "    '5': ('A', 'B'),\n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if RIP(jt):\n",
    "    marks += 1\n",
    "    \n",
    "G = Graph({\n",
    "    '1': ('2', ),\n",
    "    '2': ('1', '3'),\n",
    "    '3': ('2', '4'),\n",
    "    '4': ('3', '5'),\n",
    "    '5': ('4', ),\n",
    "})\n",
    "\n",
    "\n",
    "S = {\n",
    "    '12': ('A', 'B'),\n",
    "    '23': ('A', 'B'),\n",
    "    '34': ('B'),\n",
    "    '45': ('B'),\n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('A', 'B'),\n",
    "    '2': ('A', 'B'),\n",
    "    '3': ('A', 'B'),\n",
    "    '4': ('B'),\n",
    "    '5': ('A', 'B'),\n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if not RIP(jt):\n",
    "    marks += 1\n",
    "      \n",
    "G = Graph({\n",
    "    '1': ('2', ),\n",
    "    '2': ('1', '3'),\n",
    "    '3': ('2', '4'),\n",
    "    '4': ('3', '5'),\n",
    "    '5': ('4', ),\n",
    "})\n",
    "\n",
    "\n",
    "S = {\n",
    "    '12': ('A', 'B'),\n",
    "    '23': ('A', 'B'),\n",
    "    '34': ('A'),\n",
    "    '45': ('A'),\n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('A', 'B'),\n",
    "    '2': ('A', 'B'),\n",
    "    '3': ('A', 'B'),\n",
    "    '4': ('A'),\n",
    "    '5': ('A', 'B'),\n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if not RIP(jt):\n",
    "    marks += 1\n",
    "    \n",
    "G = Graph({\n",
    "    '1': ('2', ),\n",
    "    '2': ('1', '3'),\n",
    "    '3': ('2', '4'),\n",
    "    '4': ('3', '5'),\n",
    "    '5': ('4', ),\n",
    "})\n",
    "\n",
    "S = {\n",
    "    '12': ('A', 'B'),\n",
    "    '23': ('A', 'B'),\n",
    "    '34': ('A', 'B'),\n",
    "    '45': ('A', 'B'),\n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('A', 'B'),\n",
    "    '2': ('A', 'B'),\n",
    "    '3': ('A', 'B'),\n",
    "    '4': ('A', 'B'),\n",
    "    '5': ('A', 'B'),\n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if RIP(jt):\n",
    "    marks += 1\n",
    "    \n",
    "G = Graph({\n",
    "    '1': ('2', ),\n",
    "    '2': ('1', '3'),\n",
    "    '3': ('2', '4'),\n",
    "    '4': ('3', '5'),\n",
    "    '5': ('4', ),\n",
    "})\n",
    "\n",
    "S = {\n",
    "    '12': ('A', 'B'),\n",
    "    '23': ('B'),\n",
    "    '34': ('B'),\n",
    "    '45': ('A', 'B'),\n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('A', 'B'),\n",
    "    '2': ('A', 'B'),\n",
    "    '3': ('B'),\n",
    "    '4': ('A', 'B'),\n",
    "    '5': ('A', 'B'),\n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if not RIP(jt):\n",
    "    marks += 1\n",
    "    \n",
    "G = Graph({\n",
    "    '1': ('2', ),\n",
    "    '2': ('1', '3'),\n",
    "    '3': ('2', '4'),\n",
    "    '4': ('3', '5'),\n",
    "    '5': ('4', ),\n",
    "})\n",
    "\n",
    "S = {\n",
    "    '12': ('A', 'B'),\n",
    "    '23': ('A'),\n",
    "    '34': ('A'),\n",
    "    '45': ('A', 'B'),\n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('A', 'B'),\n",
    "    '2': ('A', 'B'),\n",
    "    '3': ('A'),\n",
    "    '4': ('A', 'B'),\n",
    "    '5': ('A', 'B'),\n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if not RIP(jt):\n",
    "    marks += 1\n",
    "    \n",
    "G = Graph({\n",
    "    '1': ('2', ),\n",
    "    '2': ('1', ),\n",
    "})\n",
    "\n",
    "S = {\n",
    "    '12': ('A', 'B', 'C', 'D', 'E', 'F'),\n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('A', 'B', 'C', 'D', 'E', 'F'),\n",
    "    '2': ('A', 'B', 'C', 'D', 'E', 'F'),\n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "print(RIP(jt))\n",
    "if RIP(jt):\n",
    "    marks += 1    \n",
    "\n",
    "print()\n",
    "print('Total marks: ', marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "### Question 9 [15 marks]\n",
    "\n",
    "Fill in the `likelihood_weighted_sampling` method on the GaussianBayesNet class. The section to be filled in is shown with `... #TODO`. Note that each factor in the Bayes Net will be a Gaussian Factor object.\n",
    "\n",
    "The GaussianFactor class is provided below for your convenience.\n",
    "\n",
    "Note that this question will be autotested, so do not change any code outside of the area specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our answer for Question 8 here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class GaussianBayesNet():\n",
    "    def __init__(self, graph, factor_dict=None):\n",
    "        self.graph = graph\n",
    "        self.outcomeSpace = dict()\n",
    "        self.factors = dict()\n",
    "        if factor_dict is not None:\n",
    "            self.factors = factor_dict\n",
    "    \n",
    "    def likelihood_weighted_sampling(self, n_samples, **evidence):\n",
    "        '''\n",
    "        This function returns a list of samples drawn randomly from the BayesNet distribution.\n",
    "        Arguments:\n",
    "            `n_samples`: number of samples to generate\n",
    "            `evidence`: a dictionary of observations\n",
    "        \n",
    "        returns: \n",
    "            weights: List of weights. E.g. [6.823e-05, 1.1409e-50,]\n",
    "            samples: List of sample dicts. E.g. [{'A':0.3, 'B':-1.7, 'C':1.1},{'A':-0.2, 'B':2.01, 'C':2.1},]\n",
    "        '''\n",
    "        \n",
    "        ########### Answer below\n",
    "        \n",
    "        order = self.graph.topological_sort()\n",
    "\n",
    "        samples = []\n",
    "        weights = []\n",
    "        for i in range(n_samples):\n",
    "            sigma = {}\n",
    "            w = 1\n",
    "            for var in order:\n",
    "                if var not in evidence.keys():\n",
    "                    sigma[var] = self.factors[var].sample(**sigma)[var]\n",
    "                else:\n",
    "                    sigma[var] = evidence[var]\n",
    "                    entry = tuple(sigma[v] for v in self.factors[var].domain)\n",
    "                    w *= self.factors[var].density(np.array(entry))\n",
    "            samples.append(sigma) \n",
    "            weights.append(w)        \n",
    "        ###########\n",
    "        \n",
    "        return weights, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# Test code\n",
    "\n",
    "graph = Graph({'A':['B'], 'B':['C'], 'C':[]})\n",
    "\n",
    "gbn = GaussianBayesNet(graph)\n",
    "gbn.factors['A'] = GaussianFactor(['A'], mu=1, sigma=1**2)\n",
    "gbn.factors['B'] = GaussianFactor(['B','A'], beta=[3], b_mean=0, b_var=0.2**2)\n",
    "gbn.factors['C'] = GaussianFactor(['C','B'], beta=[-3], b_mean=1, b_var=0.2**2)\n",
    "\n",
    "weights, samples = gbn.likelihood_weighted_sampling(5,B=2.7)\n",
    "\n",
    "print(samples)\n",
    "print(sum(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for testing\n",
    "\n",
    "def get_estimated_mean_cov(domain, weights, samples, evidence):\n",
    "    domain = list(k for k in domain if k not in evidence)\n",
    "    tmp = []\n",
    "    for s in samples:\n",
    "        tmp.append(list([s[key] for key in domain]))\n",
    "\n",
    "    sample_array = np.array(tmp)\n",
    "    sample_weights = (np.array(weights).reshape((-1,1)))\n",
    "    \n",
    "    estimated_mean = np.sum((sample_weights/np.sum(sample_weights))*sample_array,axis=0)\n",
    "    \n",
    "    estimated_cov = (1/(np.sum(sample_weights)-1))*(sample_weights*(sample_array-estimated_mean)).T@(sample_array-estimated_mean)\n",
    "    \n",
    "    return estimated_mean, estimated_cov\n",
    "\n",
    "def model1():\n",
    "    \n",
    "    # Model\n",
    "    evidence = {'B':2.7}\n",
    "    \n",
    "    graph = Graph({'A':['B'], 'B':['C'], 'C':[]})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['A'] = GaussianFactor(['A'], mu=1, sigma=1**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','A'], beta=[3], b_mean=0, b_var=0.2**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','B'], beta=[-3], b_mean=1, b_var=0.2**2)\n",
    "    \n",
    "    return gbn, evidence\n",
    "\n",
    "def test(gbn, evidence):\n",
    "    ### Testing\n",
    "    full_factor = GaussianFactor(tuple(), mu=[], sigma=[[]])\n",
    "    for f in gbn.factors.values():\n",
    "        full_factor = full_factor*f\n",
    "\n",
    "    weights, samples = gbn.likelihood_weighted_sampling(1000,**evidence)\n",
    "\n",
    "    # fix domain order\n",
    "    domain_order = list(samples[0].keys())\n",
    "    full_factor = full_factor._extend(domain_order)\n",
    "    true_factor = full_factor.evidence(**evidence)\n",
    "\n",
    "    mean, cov = get_estimated_mean_cov(domain_order, weights, samples, evidence)\n",
    "    sample_size = np.sum(weights)\n",
    "\n",
    "\n",
    "\n",
    "    mu_deviation = np.abs(mean-true_factor.mean())\n",
    "    \n",
    "    cov_deviation = np.abs(cov-true_factor.covariance())\n",
    "\n",
    "    # check that all evidence is equal to the observation\n",
    "    tmp = []\n",
    "    for s in samples:\n",
    "        tmp.append(list([s[key] for key in evidence]))\n",
    "    evi_equal = np.all(np.array(tmp) == np.array([e for e in evidence.values()]))\n",
    "    \n",
    "    return mu_deviation, cov_deviation, evi_equal\n",
    "\n",
    "\n",
    "def get_threshold(model):\n",
    "    mu_devs, cov_devs = [],[]\n",
    "    gbn, evidence = model()\n",
    "    for i in range(200):\n",
    "        mu_dev, cov_dev, _ = test(gbn,evidence)\n",
    "        mu_devs.append(mu_dev)\n",
    "        cov_devs.append(cov_dev)\n",
    "    return 1.2*np.max(mu_devs,axis=0), 1.2*np.max(cov_devs, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example output:\n",
    "```\n",
    "[{'A': 0.348216516404394, 'B': 2.7, 'C': -7.188024942397417}, {'A': 0.01839518456395206, 'B': 2.7, 'C': -7.103155084034539}, {'A': 1.1960021809931205, 'B': 2.7, 'C': -6.979657064371987}, {'A': 0.39587510763503886, 'B': 2.7, 'C': -6.978733681701745}, {'A': 0.9996062580578883, 'B': 2.7, 'C': -7.014497964752619}]\n",
    "[2.656373475856643e-15, 2.118460658582052e-38, 0.00010448721114381634, 7.638040102473492e-13, 0.6533391788451658]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2():\n",
    "    # Model\n",
    "    evidence = {}\n",
    "    \n",
    "    graph = Graph({'A':['B'], 'B':['C'], 'C':[]})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['A'] = GaussianFactor(['A'], mu=1, sigma=1**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','A'], beta=[3], b_mean=0, b_var=0.2**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','B'], beta=[-3], b_mean=1, b_var=0.2**2)\n",
    "    return gbn, evidence\n",
    "    \n",
    "    \n",
    "def model3():\n",
    "    # Model\n",
    "    evidence = {'A':2.0}\n",
    "    \n",
    "    graph = Graph({'A':['B'], 'B':['C'], 'C':[]})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['A'] = GaussianFactor(['A'], mu=1, sigma=1**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','A'], beta=[3], b_mean=0, b_var=0.2**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','B'], beta=[-3], b_mean=1, b_var=0.2**2)\n",
    "    return gbn, evidence\n",
    "\n",
    "def model4():\n",
    "    # Model\n",
    "    evidence = {'C':-8.0}\n",
    "    \n",
    "    graph = Graph({'A':['B'], 'B':['C'], 'C':[]})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['A'] = GaussianFactor(['A'], mu=1, sigma=1**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','A'], beta=[3], b_mean=0, b_var=0.2**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','B'], beta=[-3], b_mean=1, b_var=0.2**2)\n",
    "    return gbn, evidence\n",
    "\n",
    "def model5():\n",
    "    # Model\n",
    "    evidence = {'C':-8.0,'A':1.1}\n",
    "    \n",
    "    graph = Graph({'A':['B'], 'B':['C'], 'C':[]})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['A'] = GaussianFactor(['A'], mu=1, sigma=1**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','A'], beta=[3], b_mean=0, b_var=0.2**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','B'], beta=[-3], b_mean=1, b_var=0.2**2)\n",
    "    return gbn, evidence\n",
    "\n",
    "def model6():\n",
    "    # Model\n",
    "    evidence = {}\n",
    "    \n",
    "    graph = Graph({'D':['E','C'], 'E':['B'], 'B':['A'], 'A':[], 'C':['A']})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['D'] = GaussianFactor(['D'], mu=0, sigma=1**2)\n",
    "    gbn.factors['E'] = GaussianFactor(['E','D'], beta=[0.5], b_mean=0.4, b_var=0.2**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','E'], beta=[-0.1], b_mean=1, b_var=0.3**2)\n",
    "    gbn.factors['A'] = GaussianFactor(['A','B','C'], beta=[-0.9, 2], b_mean=1, b_var=0.3**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','D'], beta=[-2.3], b_mean=-1, b_var=0.5**2)\n",
    "    \n",
    "    return gbn, evidence\n",
    "\n",
    "\n",
    "def model7():\n",
    "    # Model\n",
    "    evidence = {'D':0.4}\n",
    "    \n",
    "    graph = Graph({'D':['E','C'], 'E':['B'], 'B':['A'], 'A':[], 'C':['A']})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['D'] = GaussianFactor(['D'], mu=0, sigma=1**2)\n",
    "    gbn.factors['E'] = GaussianFactor(['E','D'], beta=[0.5], b_mean=0.4, b_var=0.2**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','E'], beta=[-0.1], b_mean=1, b_var=0.3**2)\n",
    "    gbn.factors['A'] = GaussianFactor(['A','B','C'], beta=[-0.9, 2], b_mean=1, b_var=0.3**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','D'], beta=[-2.3], b_mean=-1, b_var=0.5**2)\n",
    "    \n",
    "    return gbn, evidence\n",
    "\n",
    "def model8():\n",
    "    # Model\n",
    "    evidence = {'A':-2}\n",
    "    \n",
    "    graph = Graph({'D':['C','E'], 'E':['B'], 'B':['A'], 'A':[], 'C':['A']})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['D'] = GaussianFactor(['D'], mu=0.1, sigma=1.1**2)\n",
    "    gbn.factors['E'] = GaussianFactor(['E','D'], beta=[0.6], b_mean=0.31, b_var=0.32**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','E'], beta=[-0.1], b_mean=1, b_var=0.1**2)\n",
    "    gbn.factors['A'] = GaussianFactor(['A','B','C'], beta=[-0.9, 2], b_mean=1, b_var=0.3**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','D'], beta=[-2.3], b_mean=-1, b_var=0.5**2)\n",
    "    \n",
    "    return gbn, evidence\n",
    "\n",
    "def model9():\n",
    "    # Model\n",
    "    evidence = {'A':-2,'E':0.3}\n",
    "    \n",
    "    graph = Graph({'D':['C','E'], 'E':['B'], 'B':['A'], 'A':[], 'C':['A']})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['D'] = GaussianFactor(['D'], mu=0.1, sigma=1.1**2)\n",
    "    gbn.factors['E'] = GaussianFactor(['E','D'], beta=[0.6], b_mean=0.31, b_var=0.32**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','E'], beta=[-0.1], b_mean=1, b_var=0.1**2)\n",
    "    gbn.factors['A'] = GaussianFactor(['A','B','C'], beta=[-0.9, 2], b_mean=1, b_var=0.3**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','D'], beta=[-2.3], b_mean=-1, b_var=0.5**2)\n",
    "    \n",
    "    return gbn, evidence\n",
    "\n",
    "def model10():\n",
    "    # Model\n",
    "    evidence = {'E':0.3,'B':1,'C':-1}\n",
    "    \n",
    "    graph = Graph({'D':['C','E'], 'E':['B'], 'B':['A'], 'A':[], 'C':['A']})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['D'] = GaussianFactor(['D'], mu=0.1, sigma=1.1**2)\n",
    "    gbn.factors['E'] = GaussianFactor(['E','D'], beta=[0.6], b_mean=0.31, b_var=0.32**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','E'], beta=[-0.1], b_mean=1, b_var=0.1**2)\n",
    "    gbn.factors['A'] = GaussianFactor(['A','B','C'], beta=[-0.9, 2], b_mean=1, b_var=0.3**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','D'], beta=[-2.3], b_mean=-1, b_var=0.5**2)\n",
    "    \n",
    "    return gbn, evidence\n",
    "\n",
    "def model11():\n",
    "    # Model\n",
    "    evidence = {'A': -115}\n",
    "    \n",
    "    graph = Graph({'D':['C'], 'E':['B','C'], 'B':['A'], 'A':[], 'C':['A'],'F':['A']})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['D'] = GaussianFactor(['D'], mu=0.1, sigma=1.1**2)\n",
    "    gbn.factors['E'] = GaussianFactor(['E'], mu=-5.1, sigma=0.1**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','E'], beta=[-2.1], b_mean=1, b_var=0.1**2)\n",
    "    gbn.factors['A'] = GaussianFactor(['A','B','C','F'], beta=[-0.9, 2, 0.05], b_mean=1, b_var=0.3**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','D','E'], beta=[-2.3,10], b_mean=-1, b_var=0.5**2)\n",
    "    gbn.factors['F'] = GaussianFactor(['F'], mu=50, sigma=6**2)\n",
    "    \n",
    "    return gbn, evidence\n",
    "\n",
    "def model12():\n",
    "    # Model\n",
    "    evidence = {'A': -115, 'C':-53}\n",
    "    \n",
    "    graph = Graph({'D':['C'], 'E':['B','C'], 'B':['A'], 'A':[], 'C':['A'],'F':['A'],'G':['A']})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['D'] = GaussianFactor(['D'], mu=0.1, sigma=1.1**2)\n",
    "    gbn.factors['E'] = GaussianFactor(['E'], mu=-5.1, sigma=0.1**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','E'], beta=[-2.1], b_mean=1, b_var=0.1**2)\n",
    "    gbn.factors['A'] = GaussianFactor(['A','B','C','F','G'], beta=[-0.9, 2, 0.05, 3], b_mean=1, b_var=0.3**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','D','E'], beta=[-2.3,10], b_mean=-1, b_var=0.5**2)\n",
    "    gbn.factors['F'] = GaussianFactor(['F'], mu=50, sigma=6**2)\n",
    "    gbn.factors['G'] = GaussianFactor(['G'], mu=0, sigma=0.4**2)\n",
    "    \n",
    "    return gbn, evidence\n",
    "\n",
    "def model13():\n",
    "    # Model\n",
    "    evidence = {'G':0.2,'A':-115}\n",
    "    \n",
    "    graph = Graph({'D':['C'], 'E':['B','C'], 'B':['A'], 'A':[], 'C':['A'],'F':['A'],'G':['A']})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['D'] = GaussianFactor(['D'], mu=0.1, sigma=1.1**2)\n",
    "    gbn.factors['E'] = GaussianFactor(['E'], mu=-5.1, sigma=0.1**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','E'], beta=[-2.1], b_mean=1, b_var=0.1**2)\n",
    "    gbn.factors['A'] = GaussianFactor(['A','B','C','F','G'], beta=[-0.9, 2, 0.05, 3], b_mean=1, b_var=0.3**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','D','E'], beta=[-2.3,10], b_mean=-1, b_var=0.5**2)\n",
    "    gbn.factors['F'] = GaussianFactor(['F'], mu=50, sigma=6**2)\n",
    "    gbn.factors['G'] = GaussianFactor(['G'], mu=0, sigma=0.4**2)\n",
    "    \n",
    "    return gbn, evidence\n",
    "\n",
    "def model14():\n",
    "    # Model\n",
    "    evidence = {}\n",
    "    \n",
    "    graph = Graph({'D':['C'], 'E':['B','C'], 'B':['A'], 'A':[], 'C':['A'],'F':['A'],'G':['A']})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['D'] = GaussianFactor(['D'], mu=0.1, sigma=1.1**2)\n",
    "    gbn.factors['E'] = GaussianFactor(['E'], mu=-5.1, sigma=0.1**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','E'], beta=[-2.1], b_mean=1, b_var=0.1**2)\n",
    "    gbn.factors['A'] = GaussianFactor(['A','B','C','F','G'], beta=[-0.9, 2, 0.05, 3], b_mean=1, b_var=0.3**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','D','E'], beta=[-2.3,10], b_mean=-1, b_var=0.5**2)\n",
    "    gbn.factors['F'] = GaussianFactor(['F'], mu=50, sigma=6**2)\n",
    "    gbn.factors['G'] = GaussianFactor(['G'], mu=0, sigma=0.4**2)\n",
    "    \n",
    "    return gbn, evidence\n",
    "\n",
    "def model15():\n",
    "    # Model\n",
    "    evidence = {'E':-4.9}\n",
    "    \n",
    "    graph = Graph({'D':['C'], 'E':['B','C'], 'B':['A'], 'A':[], 'C':['A'],'F':['A'],'G':['A']})\n",
    "\n",
    "    gbn = GaussianBayesNet(graph)\n",
    "    gbn.factors['D'] = GaussianFactor(['D'], mu=0.1, sigma=1.1**2)\n",
    "    gbn.factors['E'] = GaussianFactor(['E'], mu=-5.1, sigma=0.1**2)\n",
    "    gbn.factors['B'] = GaussianFactor(['B','E'], beta=[-2.1], b_mean=1, b_var=0.1**2)\n",
    "    gbn.factors['A'] = GaussianFactor(['A','B','C','F','G'], beta=[-0.9, 2, 0.05, 3], b_mean=1, b_var=0.3**2)\n",
    "    gbn.factors['C'] = GaussianFactor(['C','D','E'], beta=[-2.3,10], b_mean=-1, b_var=0.5**2)\n",
    "    gbn.factors['F'] = GaussianFactor(['F'], mu=50, sigma=6**2)\n",
    "    gbn.factors['G'] = GaussianFactor(['G'], mu=0, sigma=0.4**2)\n",
    "    \n",
    "    return gbn, evidence\n",
    "\n",
    "\n",
    "\n",
    "gbn, evidence = model13()\n",
    "weights, samples = gbn.likelihood_weighted_sampling(50, **evidence)\n",
    "print(sum(weights))\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes a long time to run, and shouldn't be used with student code.\n",
    "# dump thresholds calculated using solution code, for testing student solutions.\n",
    "# The thresholds show how much random deviation is acceptable.\n",
    "import pickle\n",
    "for i, model in enumerate([model1,model2,model3,model4,model5,model6,model7,model8,model9,model10,model11,model12,model13,model14,model15]):\n",
    "    thresholds = get_threshold(model)\n",
    "    pickle.dump(thresholds, open( f\"{i}.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import pickle\n",
    "\n",
    "# For testing student solutions, should be copied \n",
    "# along with testing functions above into student \n",
    "# code, which should be in a subfolder. The outer folder\n",
    "# should contain the .pkl threshold files.\n",
    "\n",
    "marks = 0\n",
    "for i, model in enumerate([model1, model2, model3, model4, model5, model6, model7, model8, model9, model10,model11,model12,model13,model14,model15]):\n",
    "    thresholds = pickle.load(open(f\"{i}.pkl\", 'rb'))\n",
    "    mu_threshold, cov_threshold = thresholds\n",
    "    gbn, evidence = model()\n",
    "    try:\n",
    "        mu_dev, cov_dev, evi_equal = test(gbn, evidence)\n",
    "        if evi_equal and np.all(mu_dev < mu_threshold) and np.all(cov_dev < cov_threshold):\n",
    "            marks += 1\n",
    "        else:\n",
    "            print(f\"#### failed model {i+1}\")\n",
    "            full_factor = GaussianFactor(tuple(), mu=[], sigma=[[]])\n",
    "            for f in gbn.factors.values():\n",
    "                full_factor = full_factor*f\n",
    "\n",
    "            weights, samples = gbn.likelihood_weighted_sampling(1000,**evidence)\n",
    "            # fix domain order\n",
    "            domain_order = list(samples[0].keys())\n",
    "            full_factor = full_factor._extend(domain_order)\n",
    "            true_factor = full_factor.evidence(**evidence)\n",
    "            mean, cov = get_estimated_mean_cov(domain_order, weights, samples, evidence)\n",
    "            sample_size = np.sum(weights)\n",
    "            print(f\"True domain {true_factor.domain}\")\n",
    "            print(f\"True mean: {true_factor.mean()}\")\n",
    "            print(f\"Est mean: {mean}\")\n",
    "            print(f\"Samples: {samples[0:10]}\")\n",
    "            print(f\"Evi equal: {evi_equal}\")\n",
    "            if(not np.all(mu_dev < mu_threshold)):\n",
    "                print(\"source: mu\")\n",
    "            elif(not np.all(cov_dev < cov_threshold)):\n",
    "                print(\"source: cov\")\n",
    "            print(\"#######\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in model {i+1}\")\n",
    "        traceback.print_tb(e.__traceback__)\n",
    "\n",
    "print(\"Total marks Q9\",marks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "198px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "783px",
    "left": "0px",
    "right": "1346.87px",
    "top": "108px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
